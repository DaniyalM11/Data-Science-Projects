{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f62ee3",
   "metadata": {},
   "source": [
    "## MNist Deep Dive Project\n",
    "\n",
    "### By Daniyal Mufti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dae683",
   "metadata": {},
   "source": [
    "In this project we will do a deep dive on the famous MNist dataset applying various classification models along with augmenting the data to see if we can achieve SOTA performance on the dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f3cdb2",
   "metadata": {},
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c390382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4382940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's fetch the data\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84be2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d201faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to plot a digit\n",
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03af3303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's split the data into Train and Test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9223470",
   "metadata": {},
   "source": [
    "##### Let's create an augemented dataset with shifted images of instances added to it.  We will test if that helps lower our classification error.\n",
    "\n",
    "##### Note we only need to augement the training datasets as the test datasets are kept  to see if the augementation helps with lower the classification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6ab0a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 784) (300000,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "# A helper function to shift our MNist dataset instance\n",
    "def shift_digit(digit_array, dx, dy, new=0):\n",
    "    return shift(digit_array.reshape(28, 28), [dy, dx], cval=new).reshape(784)\n",
    "\n",
    "# Let's create our augemented Training dataset\n",
    "\n",
    "X_train_expanded = [X_train]\n",
    "y_train_expanded = [y_train]\n",
    "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "    shifted_images = np.apply_along_axis(shift_digit, axis=1, arr=X_train, dx=dx, dy=dy)\n",
    "    X_train_expanded.append(shifted_images)\n",
    "    y_train_expanded.append(y_train)\n",
    "\n",
    "X_train_expanded = np.concatenate(X_train_expanded)\n",
    "y_train_expanded = np.concatenate(y_train_expanded)\n",
    "print(X_train_expanded.shape, y_train_expanded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e552aaa1",
   "metadata": {},
   "source": [
    "### 2. Test Predictive Models\n",
    "\n",
    "##### So now we have two training datasets. Let's try using some predictive models and see how they perform on both those datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3ca2e",
   "metadata": {},
   "source": [
    "##### a. KNN Classifier\n",
    "\n",
    "Lets start with weights hyperparameter equal to distance and number of neighbours equal to 4. Later on we can do grid search to find the best hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3029309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import KNN Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09b9b0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regular Dataset\n",
    "knn_clf = KNeighborsClassifier(weights='distance', n_neighbors=4)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_knn_pred = knn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "441e0fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Augemented Dataset\n",
    "knn_clf_aug = KNeighborsClassifier(weights='distance', n_neighbors=4)\n",
    "knn_clf_aug.fit(X_train_expanded, y_train_expanded)\n",
    "y_knn_aug_pred = knn_clf_aug.predict(X_test)\n",
    "accuracy_score(y_test, y_knn_aug_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb4b8e",
   "metadata": {},
   "source": [
    "##### Great! By the looks of it, augementing the data gives us a greater accuracy score. Let's try scaling the feature set and see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90fedfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float32))\n",
    "X_test_scaled = scaler.transform(X_test.astype(np.float32))\n",
    "X_train_expanded_scaled = scaler.fit_transform(X_train_expanded.astype(np.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "293a337f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9489"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regular Dataset Scaled\n",
    "knn_clf_scaled = KNeighborsClassifier(weights='distance', n_neighbors=4)\n",
    "knn_clf_scaled.fit(X_train_scaled, y_train)\n",
    "y_knn_scaled_pred = knn_clf_scaled.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_knn_scaled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f365620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9584"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Augemented Dataset Scaled\n",
    "knn_clf_aug_scaled = KNeighborsClassifier(weights='distance', n_neighbors=4)\n",
    "knn_clf_aug_scaled.fit(X_train_expanded_scaled, y_train_expanded)\n",
    "y_knn_aug_scaled_pred = knn_clf_aug_scaled.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_knn_aug_scaled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6999608d",
   "metadata": {},
   "source": [
    "##### Unfortunately it seems like scaling the data did not help our KNN classifier achieve a greater accuracy(though augementing helped even with the scaled datasets).  \n",
    "\n",
    "Let's try grid search but let's use the datasets which have been augemented but not scaled and see if we can get greater accuracy scores from hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5caeef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END ....n_neighbors=3, weights=uniform;, score=0.995 total time= 4.1min\n",
      "[CV 2/5] END ....n_neighbors=3, weights=uniform;, score=0.963 total time= 4.1min\n",
      "[CV 3/5] END ....n_neighbors=3, weights=uniform;, score=0.959 total time= 4.1min\n",
      "[CV 4/5] END ....n_neighbors=3, weights=uniform;, score=0.973 total time= 4.1min\n",
      "[CV 5/5] END ....n_neighbors=3, weights=uniform;, score=0.969 total time= 4.1min\n",
      "[CV 1/5] END ...n_neighbors=3, weights=distance;, score=0.995 total time= 4.1min\n",
      "[CV 2/5] END ...n_neighbors=3, weights=distance;, score=0.964 total time= 4.1min\n",
      "[CV 3/5] END ...n_neighbors=3, weights=distance;, score=0.961 total time= 4.1min\n",
      "[CV 4/5] END ...n_neighbors=3, weights=distance;, score=0.976 total time= 4.1min\n",
      "[CV 5/5] END ...n_neighbors=3, weights=distance;, score=0.972 total time= 4.1min\n",
      "[CV 1/5] END ....n_neighbors=4, weights=uniform;, score=0.992 total time= 5.0min\n",
      "[CV 2/5] END ....n_neighbors=4, weights=uniform;, score=0.960 total time= 5.0min\n",
      "[CV 3/5] END ....n_neighbors=4, weights=uniform;, score=0.950 total time= 5.1min\n",
      "[CV 4/5] END ....n_neighbors=4, weights=uniform;, score=0.969 total time= 5.1min\n",
      "[CV 5/5] END ....n_neighbors=4, weights=uniform;, score=0.962 total time= 5.2min\n",
      "[CV 1/5] END ...n_neighbors=4, weights=distance;, score=0.995 total time= 5.1min\n",
      "[CV 2/5] END ...n_neighbors=4, weights=distance;, score=0.966 total time= 5.1min\n",
      "[CV 3/5] END ...n_neighbors=4, weights=distance;, score=0.962 total time= 5.1min\n",
      "[CV 4/5] END ...n_neighbors=4, weights=distance;, score=0.977 total time= 5.1min\n",
      "[CV 5/5] END ...n_neighbors=4, weights=distance;, score=0.973 total time= 5.5min\n",
      "[CV 1/5] END ....n_neighbors=5, weights=uniform;, score=0.993 total time= 5.4min\n",
      "[CV 2/5] END ....n_neighbors=5, weights=uniform;, score=0.959 total time= 5.2min\n",
      "[CV 3/5] END ....n_neighbors=5, weights=uniform;, score=0.952 total time= 5.0min\n",
      "[CV 4/5] END ....n_neighbors=5, weights=uniform;, score=0.967 total time= 5.1min\n",
      "[CV 5/5] END ....n_neighbors=5, weights=uniform;, score=0.963 total time= 5.4min\n",
      "[CV 1/5] END ...n_neighbors=5, weights=distance;, score=0.993 total time= 5.3min\n",
      "[CV 2/5] END ...n_neighbors=5, weights=distance;, score=0.961 total time= 5.7min\n",
      "[CV 3/5] END ...n_neighbors=5, weights=distance;, score=0.955 total time= 5.7min\n",
      "[CV 4/5] END ...n_neighbors=5, weights=distance;, score=0.970 total time= 5.2min\n",
      "[CV 5/5] END ...n_neighbors=5, weights=distance;, score=0.967 total time= 5.3min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{'n_neighbors': [3, 4, 5],\n",
       "                          'weights': ['uniform', 'distance']}],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [3, 4, 5]}]\n",
    "\n",
    "knn_clf_gridSearch = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn_clf_gridSearch, param_grid, cv=5, verbose=3)\n",
    "grid_search.fit(X_train_expanded, y_train_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "219deb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "549c5f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9747666666666668"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac48aadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_gridSearch = grid_search.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_gridSearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf12cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b1e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
