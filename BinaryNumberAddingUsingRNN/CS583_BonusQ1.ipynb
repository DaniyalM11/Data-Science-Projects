{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04d4bef5",
   "metadata": {},
   "source": [
    "##### CS 583 Bonus Question 1\n",
    "\n",
    "I will use Tensorflow implemented Kera's RNN implementation with a custom RNN cell. The Keras sequantial API allows us a custom RNN Cell with keras.layer.RNN, to get a custom RNN layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c827113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, activations, models\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524526b0",
   "metadata": {},
   "source": [
    "Lets create our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44ce8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bits = 8\n",
    "n_samples = 100000\n",
    "samples = np.random.randint(np.power(2, max_bits-1), size=(n_samples, 2))\n",
    "summed_samples = np.sum(samples, axis=1)\n",
    "samples_binary_repr = [[np.binary_repr(a, width=max_bits), np.binary_repr(b, width=max_bits)] for a,b in samples]\n",
    "summed_binary_repr = [np.binary_repr(c, width=max_bits) for c in summed_samples]\n",
    "x_str = np.array([[list(a), list(b)] for a, b in samples_binary_repr])\n",
    "y_str = np.array([list(c) for c in summed_binary_repr])\n",
    "x_flipped = np.flip(x_str, axis=-1)\n",
    "y_flipped = np.flip(y_str, axis=-1)\n",
    "x = np.transpose((x_flipped == '1')*1, axes=(0, 2, 1))\n",
    "y = (y_flipped == '1')*1\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8e073",
   "metadata": {},
   "source": [
    "Create the custom RNN cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15ab8137",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Addcell(layers.Layer):\n",
    "    def __init__(self, hidden_units, **kwargs):\n",
    "        super(Addcell, self).__init__(**kwargs)\n",
    "        self.units = 1\n",
    "        self.state_size = 1\n",
    "        self.hidden_units = hidden_units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.hidden_kernel = self.add_weight(shape=(input_shape[-1] + self.state_size, self.hidden_units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='hidden_kernel')\n",
    "        self.hidden_bias = self.add_weight(shape=(1, self.hidden_units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='hidden_bias')\n",
    "        self.output_kernel = self.add_weight(shape=(self.hidden_units, self.units + self.state_size),\n",
    "                                      initializer='uniform',\n",
    "                                      name='output_kernel')\n",
    "        self.output_bias = self.add_weight(shape=(1, self.units + self.state_size),\n",
    "                                      initializer='uniform',\n",
    "                                      name='output_bias')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        x = tf.concat([inputs, states[0]], axis=-1)\n",
    "        h = tf.keras.activations.tanh(tf.matmul(x, self.hidden_kernel) + self.hidden_bias)\n",
    "        o_s = tf.keras.activations.sigmoid(tf.matmul(h, self.output_kernel) + self.output_bias)\n",
    "        output = o_s[:, :self.units]\n",
    "        state = o_s[:, self.units:]\n",
    "        return output, [state]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc412472",
   "metadata": {},
   "source": [
    "Lets create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65898271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Add_Cell\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn_5 (RNN)                  (None, None, 1)           20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(name='Add_Cell')\n",
    "model.add(layers.RNN(Addcell(3), return_sequences=True, input_shape=(None, 2)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073201fe",
   "metadata": {},
   "source": [
    "Lets train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9adf3ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2813/2813 [==============================] - 5s 2ms/step - loss: 0.6925 - accuracy: 0.4990\n",
      "Epoch 2/60\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 0.6409 - accuracy: 0.5897\n",
      "Epoch 3/60\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 0.5037 - accuracy: 0.7346\n",
      "Epoch 4/60\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 0.4465 - accuracy: 0.7459\n",
      "Epoch 5/60\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 0.4273 - accuracy: 0.7514\n",
      "Epoch 6/60\n",
      "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4227 - accuracy: 0.7514\n",
      "Epoch 7/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.4204 - accuracy: 0.7514\n",
      "Epoch 8/60\n",
      "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4192 - accuracy: 0.7514\n",
      "Epoch 9/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.4184 - accuracy: 0.7514\n",
      "Epoch 10/60\n",
      "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4179 - accuracy: 0.7514\n",
      "Epoch 11/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.4176 - accuracy: 0.7514\n",
      "Epoch 12/60\n",
      "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4173 - accuracy: 0.7514\n",
      "Epoch 13/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.4170 - accuracy: 0.7514\n",
      "Epoch 14/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.4169 - accuracy: 0.7514\n",
      "Epoch 15/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.4167 - accuracy: 0.7514\n",
      "Epoch 16/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.4166 - accuracy: 0.7514\n",
      "Epoch 17/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.4027 - accuracy: 0.7590\n",
      "Epoch 18/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.3583 - accuracy: 0.8059\n",
      "Epoch 19/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.3550 - accuracy: 0.7971\n",
      "Epoch 20/60\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 0.3541 - accuracy: 0.7966\n",
      "Epoch 21/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.3533 - accuracy: 0.7952\n",
      "Epoch 22/60\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 0.3523 - accuracy: 0.7989\n",
      "Epoch 23/60\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 0.3501 - accuracy: 0.8156\n",
      "Epoch 24/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.3416 - accuracy: 0.8310\n",
      "Epoch 25/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.3254 - accuracy: 0.8714\n",
      "Epoch 26/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.3063 - accuracy: 0.9011\n",
      "Epoch 27/60\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 0.2834 - accuracy: 0.9163\n",
      "Epoch 28/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.2510 - accuracy: 0.9212\n",
      "Epoch 29/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.2186 - accuracy: 0.9215\n",
      "Epoch 30/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.2029 - accuracy: 0.9215\n",
      "Epoch 31/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1970 - accuracy: 0.9215\n",
      "Epoch 32/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1947 - accuracy: 0.9215\n",
      "Epoch 33/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1938 - accuracy: 0.9215\n",
      "Epoch 34/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1934 - accuracy: 0.9215\n",
      "Epoch 35/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1932 - accuracy: 0.9215\n",
      "Epoch 36/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1931 - accuracy: 0.9215\n",
      "Epoch 37/60\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 0.1930 - accuracy: 0.9215\n",
      "Epoch 38/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1930 - accuracy: 0.9215\n",
      "Epoch 39/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1930 - accuracy: 0.9215\n",
      "Epoch 40/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1929 - accuracy: 0.9215\n",
      "Epoch 41/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1929 - accuracy: 0.9215\n",
      "Epoch 42/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1929 - accuracy: 0.9215\n",
      "Epoch 43/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1929 - accuracy: 0.9215\n",
      "Epoch 44/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1929 - accuracy: 0.9215\n",
      "Epoch 45/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 46/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 47/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 48/60\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 49/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 50/60\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 51/60\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 52/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 53/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 54/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 55/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 56/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 57/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1928 - accuracy: 0.9215\n",
      "Epoch 58/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1927 - accuracy: 0.9215\n",
      "Epoch 59/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1927 - accuracy: 0.9215\n",
      "Epoch 60/60\n",
      "2813/2813 [==============================] - 4s 2ms/step - loss: 0.1927 - accuracy: 0.9215\n",
      "313/313 - 0s - loss: 0.1913 - accuracy: 0.9226\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=60)\n",
    "scores = model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b84a05",
   "metadata": {},
   "source": [
    "Not too bad. Accuracy of 92%. Lets use our model to predict a sum. Adam optimizer seems to perform the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6e0e09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 11, b: 20\n",
      "In binary = a: [1. 1. 0. 1. 0. 0. 0. 0.], b: [0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "summed: 31\n",
      "In binary = summed: [1 1 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Lets see how we do with an example\n",
    "max_bits = 8\n",
    "a = np.random.randint(np.power(2, max_bits-1))\n",
    "b = np.random.randint(np.power(2, max_bits-1))\n",
    "a_bin = np.float32(1) * (np.flip(list(np.binary_repr(a, width=max_bits)), axis=-1) == '1')\n",
    "b_bin = np.float32(1) * (np.flip(list(np.binary_repr(b, width=max_bits)), axis=-1) == '1')\n",
    "print('a: {}, b: {}'.format(a, b))\n",
    "print('In binary = a: {}, b: {}'.format(a_bin, b_bin))\n",
    "a_b = np.stack((a_bin, b_bin), axis=-1).reshape(1,-1,2)\n",
    "predictions = model(a_b).numpy().flatten()\n",
    "summed_bin = 1 * (predictions > 0.5)\n",
    "summed = np.packbits(np.flip(summed_bin , axis=-1))[0]\n",
    "print('summed: {}'.format(summed))\n",
    "print('In binary = summed: {}'.format(summed_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f2293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480337d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
